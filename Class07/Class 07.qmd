---
title: "Class 07: Machine Learning 1"
author: "Destiny (A16340362)"
format: pdf
---
#Clustering
We will start today's lab with clustering methods, in particular so-called K-means. The main functions for this in R is `kmeans()`

Let's try it on some made up data where we know what the answer should be

```{r}
x <- rnorm(10000, mean=3)
hist(x)
```
60 points
```{r}
tmp <- c(rnorm(30, mean=3), rnorm(30,-3))
x <- cbind(x=tmp, y=rev(tmp))
head(x)
```
We can pass this to the base R `plot()` function for a quick plot 
```{r}
plot(x)
```
```{r}
k <- kmeans(x, centers=2, nstart= 20)
k

```

>Q.1 How many points are in each cluster 

```{r}
k$size
```

>Q.2 Cluster membership?

```{r}
k$cluster
```


>Q3. Cluster centers?

```{r}
k$centers
```

>Q4. Plot my clustering results

```{r}
plot(x, col= k$cluster, pch=16)
```



>Q5. Cluster the data again with `kmeans()`into four groups and plot the results 

```{r}
k4 <- kmeans(x, centers=4, nstart= 20)
plot(x, col= k4$cluster, pch=16)


```
K-means is very popular mostly because its fast and relatively  straightforward to run and understand. It has a big limitation in that you need to tell it how many groups (k, or centers) you want.
#Hierarchical clustering

The main function in base R is called `hclust()`. You have to pass it in a "distance matrix" not just your input data. (won't work with just the data itself, need to pass it into the distance matrix)

You can generate a distance matrix with the `dist()` function.
```{r}
hc <- hclust(dist(x))
hc
```

```{r}
plot(hc)
```

To find the clusters (cluster membership vector) from a `hclust()` result we can "cut" the tree at a certain height that we like. 
```{r}
plot(hc)
abline(h=8, col="red")
groups <- cutree(hc, h=8)
```
```{r}
table(groups)
```

>Q6. Plot our hclust results 

```{r}
plot(x, col= groups, pch=16)
```

#Principal Component Analysis 

##PCA of UK food data

Read data showing the consumption in grams (per person, per week) of 17 different types of food stuff measured and averaged in the four countries of the United Kingdom 

Let's see how PCA can help us but first we can try conventional analysis
```{r}
url <- "https://tinyurl.com/UK-foods"
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```
>Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?

```{r}
dim(x)
```
## Preview the first 6 rows
```{r}
head(x)
```
```{r}
x <- read.csv(url, row.names=1)
head(x)
```

>Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

I prefer the `r`ow.names=1` code. This approach is stronger than the x[,-1] approach because the code over writes the same object each time and it keeps getting rid of rows ever time that I run it.


```{r}
barplot(as.matrix(x), beside=T, col=rainbow(nrow(x)))

```
>Q3: Changing what optional argument in the above barplot() function results in the following plot?

```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```


```{r}
pairs(x, col=rainbow(17), pch=16, cex=2)
```
>Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

If a given point lies along the diagonal for a given plot means that the each country's consumption is about the same similarity, whereas if certain plots lie below the diagonal line this means dissimilarity and lower type of consumption. 

>Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

In this data set, the main differences between N. Ireland and the other countries in the UK is a bit more difficult to see.However, compared to the other countries in the UK and their graphs, each plot of N. Ireland vs the other UK countries has less of of a straight diagonal line indicating that it's properly more dissimilar.  



##Principal Compoenent analysis (PCA) 

PCA can help us make sense of these types of data sets. Let's see how it works. 

The main function in "base" R is called `prcomp()`. In this case, we want to first take the transpose `t()` of our input `x` so the columns are the food types and the counties are the rows 

```{r}
head(t(x))
```
```{r}
pca <- prcomp(t(x))
summary(pca)
```
>Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.

```{r}
# Plot PC1 vs PC2
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))

```


```{r}
pca$x
```
```{r}
plot(pca$x[,1], pca$x[,2], col=c("orange", "red", "blue","darkgreen"), pch=16) 
```
>Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document 

```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x), col=c("orange", "red", "blue","darkgreen"))
```

```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v

z <- summary(pca)
z$importance
```
```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")

```

The "loadings" tell us how much of the original variables (in our cause the foods, contribute) to the new variables i.e. PCs

```{r}
pca$rotation

## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```

>Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does PC2 maninly tell us about?

The two food group features that are most prominent are fresh potatoes and soft drinks. PC1 captures the most variance through a certain point, but PC2 will capture the second most variance in comparison to PC1. In other words, PC2 will be able to capture the rest of the variance that PC1 wasn't able to capture. 

```{r}
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,2], las=2 )
```

